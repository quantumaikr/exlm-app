# RunPod EXLM ì„¤ì¹˜ ì™„ì „ ê°€ì´ë“œ

RunPodì—ì„œ EXLM í”Œëž«í¼ì„ ì„¤ì¹˜í•˜ê³  ì‹¤í–‰í•˜ëŠ” ì™„ì „í•œ ë‹¨ê³„ë³„ ê°€ì´ë“œìž…ë‹ˆë‹¤.

## ðŸ“‹ ëª©ì°¨

1. [RunPod Pod ìƒì„±](#1-runpod-pod-ìƒì„±)
2. [SSH ì ‘ì†](#2-ssh-ì ‘ì†)
3. [ìžë™ ì„¤ì¹˜](#3-ìžë™-ì„¤ì¹˜)
4. [í¬íŠ¸ ì„¤ì •](#4-í¬íŠ¸-ì„¤ì •)
5. [ì ‘ì† í™•ì¸](#5-ì ‘ì†-í™•ì¸)
6. [ë¬¸ì œ í•´ê²°](#6-ë¬¸ì œ-í•´ê²°)
7. [ê´€ë¦¬ ëª…ë ¹ì–´](#7-ê´€ë¦¬-ëª…ë ¹ì–´)

## 1. RunPod Pod ìƒì„±

### 1.1 RunPod ê³„ì • ìƒì„±

1. [RunPod.io](https://runpod.io) ì ‘ì†
2. GitHub ë˜ëŠ” Google ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸
3. ê²°ì œ ì •ë³´ ë“±ë¡ (í¬ë ˆë”§ ë˜ëŠ” ì¹´ë“œ)

### 1.2 Pod ìƒì„±

1. **"Deploy"** í´ë¦­
2. **Template ì„ íƒ**: `RunPod PyTorch` ë˜ëŠ” `Ubuntu 22.04`
3. **GPU ì„ íƒ**:
   - **ìµœì†Œ**: RTX 4090 (24GB) - 7B ëª¨ë¸ í•™ìŠµ ê°€ëŠ¥
   - **ê¶Œìž¥**: RTX 4090 (24GB) - 13B ëª¨ë¸ í•™ìŠµ ê°€ëŠ¥
   - **ê³ ì„±ëŠ¥**: A100 (40GB) - 70B ëª¨ë¸ í•™ìŠµ ê°€ëŠ¥
4. **Pod ì„¤ì •**:
   - **Container Disk**: 50GB ì´ìƒ
   - **Volume Disk**: 100GB ì´ìƒ (ë°ì´í„° ì €ìž¥ìš©)
   - **Docker Image**: `runpod/pytorch:2.1.1-py3.10-cuda11.8.0-devel-ubuntu22.04`
5. **"Deploy"** í´ë¦­

### 1.3 Pod ì‹œìž‘ ëŒ€ê¸°

- Pod ìƒíƒœê°€ **"Running"**ì´ ë  ë•Œê¹Œì§€ ëŒ€ê¸° (ì•½ 2-3ë¶„)
- **"Connect"** ë²„íŠ¼ì´ í™œì„±í™”ë˜ë©´ ì¤€ë¹„ ì™„ë£Œ

## 2. SSH ì ‘ì†

### 2.1 SSH í‚¤ ì„¤ì • (ì„ íƒì‚¬í•­)

```bash
# ë¡œì»¬ì—ì„œ SSH í‚¤ ìƒì„±
ssh-keygen -t ed25519 -C "your_email@example.com"

# ê³µê°œí‚¤ë¥¼ RunPodì— ë“±ë¡
# RunPod ì›¹ ì½˜ì†” â†’ Settings â†’ SSH Keys â†’ Add Key
```

### 2.2 SSH ì ‘ì†

```bash
# RunPod ì›¹ ì½˜ì†”ì—ì„œ ì œê³µí•˜ëŠ” SSH ëª…ë ¹ì–´ ì‚¬ìš©
ssh root@[POD_IP] -p [SSH_PORT]

# ë˜ëŠ” SSH í‚¤ë¥¼ ë“±ë¡í•œ ê²½ìš°
ssh root@[POD_IP] -p [SSH_PORT] -i ~/.ssh/id_ed25519
```

### 2.3 ì ‘ì† í™•ì¸

```bash
# ì‹œìŠ¤í…œ ì •ë³´ í™•ì¸
uname -a
nvidia-smi  # GPU í™•ì¸
df -h       # ë””ìŠ¤í¬ ìš©ëŸ‰ í™•ì¸
```

## 3. ìžë™ ì„¤ì¹˜

### 3.1 ì›í´ë¦­ ì„¤ì¹˜ (ê¶Œìž¥)

```bash
# í•œ ë²ˆì˜ ëª…ë ¹ì–´ë¡œ ì™„ì „ ìžë™ ì„¤ì¹˜
curl -sSL https://raw.githubusercontent.com/quantumaikr/exlm-app/main/scripts/runpod-full-setup.sh | bash
```

**ì„¤ì¹˜ ê³¼ì • (ì•½ 10-15ë¶„)**:

- âœ… ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸
- âœ… Python 3.11, Node.js 18 ì„¤ì¹˜
- âœ… PostgreSQL, Redis ì„¤ì¹˜ ë° ì„¤ì •
- âœ… EXLM í”„ë¡œì íŠ¸ í´ë¡ 
- âœ… ë°±ì—”ë“œ/í”„ë¡ íŠ¸ì—”ë“œ ì˜ì¡´ì„± ì„¤ì¹˜
- âœ… ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜
- âœ… ì„œë¹„ìŠ¤ ìžë™ ì‹œìž‘

### 3.2 ì„¤ì¹˜ ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§

```bash
# ì‹¤ì‹œê°„ ë¡œê·¸ í™•ì¸
tail -f /workspace/exlm-app/logs/backend.log
tail -f /workspace/exlm-app/logs/frontend.log

# ì„¤ì¹˜ ìƒíƒœ í™•ì¸
cd /workspace/exlm-app
./status.sh
```

### 3.3 ì„¤ì¹˜ ì™„ë£Œ í™•ì¸

```bash
# ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
ps aux | grep -E "(uvicorn|npm|celery)"

# í¬íŠ¸ ì‚¬ìš© í™•ì¸
netstat -tulpn | grep -E ':(3000|8000|5555)'

# API ì‘ë‹µ í…ŒìŠ¤íŠ¸
curl -s http://localhost:8000/api/v1/health
```

## 4. í¬íŠ¸ ì„¤ì •

### 4.1 RunPod í¬íŠ¸ ì„¤ì •

1. **RunPod ì›¹ ì½˜ì†”** ì ‘ì†
2. Pod ê´€ë¦¬ íŽ˜ì´ì§€ì—ì„œ **"Edit"** í´ë¦­
3. **Ports** ì„¹ì…˜ì—ì„œ ë‹¤ìŒ í¬íŠ¸ë“¤ì„ **Public**ìœ¼ë¡œ ì„¤ì •:

| í¬íŠ¸ | ì„œë¹„ìŠ¤      | ì„¤ëª…            | í•„ìˆ˜ ì—¬ë¶€ |
| ---- | ----------- | --------------- | --------- |
| 3000 | Frontend    | ì›¹ UI           | âœ… í•„ìˆ˜   |
| 8000 | Backend API | API ì„œë²„        | âœ… í•„ìˆ˜   |
| 5555 | Flower      | Celery ëª¨ë‹ˆí„°ë§ | âšª ì„ íƒ   |

4. **"Save"** í´ë¦­

### 4.2 ì ‘ì† URL í™•ì¸

í¬íŠ¸ ì„¤ì • ì™„ë£Œ í›„ ë‹¤ìŒ URLë¡œ ì ‘ì†:

```bash
# Frontend (ì›¹ UI)
https://[POD_ID]-3000.proxy.runpod.net

# Backend API
https://[POD_ID]-8000.proxy.runpod.net

# API ë¬¸ì„œ
https://[POD_ID]-8000.proxy.runpod.net/docs

# Flower (ì„ íƒì‚¬í•­)
https://[POD_ID]-5555.proxy.runpod.net
```

**POD_ID í™•ì¸ ë°©ë²•**: RunPod ì›¹ ì½˜ì†”ì—ì„œ Pod ì´ë¦„ ë˜ëŠ” Connect ì •ë³´ì—ì„œ í™•ì¸

## 5. ì ‘ì† í™•ì¸

### 5.1 ì›¹ UI ì ‘ì†

1. ë¸Œë¼ìš°ì €ì—ì„œ `https://[POD_ID]-3000.proxy.runpod.net` ì ‘ì†
2. **íšŒì›ê°€ìž…** ë˜ëŠ” **ë¡œê·¸ì¸**
3. ëŒ€ì‹œë³´ë“œ í™•ì¸

### 5.2 API í…ŒìŠ¤íŠ¸

```bash
# API ìƒíƒœ í™•ì¸
curl -s https://[POD_ID]-8000.proxy.runpod.net/api/v1/health

# API ë¬¸ì„œ ì ‘ì†
# ë¸Œë¼ìš°ì €ì—ì„œ https://[POD_ID]-8000.proxy.runpod.net/docs
```

### 5.3 GPU í™•ì¸

```bash
# GPU ìƒíƒœ í™•ì¸
nvidia-smi

# PyTorch GPU ì¸ì‹ í™•ì¸
cd /workspace/exlm-app/backend
source venv/bin/activate
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
```

## 6. ë¬¸ì œ í•´ê²°

### 6.1 ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

#### ì„œë¹„ìŠ¤ê°€ ì‹œìž‘ë˜ì§€ ì•ŠìŒ

```bash
# ìƒíƒœ í™•ì¸
cd /workspace/exlm-app
./status.sh

# ë¡œê·¸ í™•ì¸
tail -f logs/backend.log
tail -f logs/frontend.log

# ì„œë¹„ìŠ¤ ìž¬ì‹œìž‘
./restart.sh
```

#### í¬íŠ¸ ì ‘ê·¼ ì•ˆë¨

```bash
# í¬íŠ¸ ì‚¬ìš© ìƒíƒœ í™•ì¸
netstat -tulpn | grep -E ':(3000|8000|5555)'

# RunPod í¬íŠ¸ ì„¤ì • ìž¬í™•ì¸
# â†’ RunPod ì›¹ ì½˜ì†”ì—ì„œ í¬íŠ¸ê°€ Publicìœ¼ë¡œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
```

#### ì˜ì¡´ì„± ì¶©ëŒ ì˜¤ë¥˜

```bash
# ì˜ì¡´ì„± ì¶©ëŒ í•´ê²° ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
cd /workspace/exlm-app/backend
chmod +x ../scripts/fix-dependencies.sh
../scripts/fix-dependencies.sh

# ìˆ˜ë™ í•´ê²°
source venv/bin/activate
pip uninstall -y transformers peft trl vllm accelerate pydantic fastapi openai anthropic
pip install "pydantic>=1.10.13,<2.0.0"
pip install "fastapi>=0.95.0,<0.105.0"
pip install "transformers>=4.36.0,<4.38.0"
pip install "vllm>=0.2.5,<0.3.0"
pip install -r requirements-gpu.txt
```

#### ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë¬¸ì œ

```bash
# PostgreSQL ìƒíƒœ í™•ì¸
systemctl status postgresql

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸
sudo -u postgres psql -c "\l" | grep exlm_db

# Redis ì—°ê²° í…ŒìŠ¤íŠ¸
redis-cli ping
```

#### GPU ì¸ì‹ ë¬¸ì œ

```bash
# NVIDIA ë“œë¼ì´ë²„ í™•ì¸
nvidia-smi

# CUDA ë²„ì „ í™•ì¸
nvcc --version

# PyTorch CUDA í™•ì¸
cd /workspace/exlm-app/backend
source venv/bin/activate
python -c "import torch; print(torch.version.cuda)"
```

### 6.2 ë¡œê·¸ ë¶„ì„

#### ì—ëŸ¬ ë¡œê·¸ ì°¾ê¸°

```bash
# ëª¨ë“  ë¡œê·¸ì—ì„œ ì—ëŸ¬ ê²€ìƒ‰
grep -i error logs/*.log

# íŠ¹ì • ì„œë¹„ìŠ¤ ì—ëŸ¬ ê²€ìƒ‰
grep -i "error\|exception\|failed" logs/backend.log
```

#### ì‹¤ì‹œê°„ ì—ëŸ¬ ëª¨ë‹ˆí„°ë§

```bash
# ì‹¤ì‹œê°„ìœ¼ë¡œ ì—ëŸ¬ ë¡œê·¸ë§Œ í™•ì¸
tail -f logs/*.log | grep -i --line-buffered "error\|exception\|failed"
```

### 6.3 ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

#### ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤

```bash
# CPU ë° ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
htop

# ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰
df -h

# GPU ì‚¬ìš©ëŸ‰
watch -n 1 nvidia-smi
```

#### ì• í”Œë¦¬ì¼€ì´ì…˜ ì„±ëŠ¥

```bash
# API ì‘ë‹µ í…ŒìŠ¤íŠ¸
curl -s http://localhost:8000/api/v1/health

# í”„ë¡ íŠ¸ì—”ë“œ ì ‘ì† í…ŒìŠ¤íŠ¸
curl -s http://localhost:3000 | head -10
```

## 7. ê´€ë¦¬ ëª…ë ¹ì–´

### 7.1 ì„œë¹„ìŠ¤ ê´€ë¦¬

```bash
cd /workspace/exlm-app

# ëª¨ë“  ì„œë¹„ìŠ¤ ì‹œìž‘
./start-all.sh

# ëª¨ë“  ì„œë¹„ìŠ¤ ì¤‘ì§€
./stop-all.sh

# ì„œë¹„ìŠ¤ ìž¬ì‹œìž‘
./restart.sh

# ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
./status.sh
```

### 7.2 ê°œë³„ ì„œë¹„ìŠ¤ ê´€ë¦¬

```bash
# ë°±ì—”ë“œë§Œ ì‹œìž‘
./start-backend.sh

# í”„ë¡ íŠ¸ì—”ë“œë§Œ ì‹œìž‘
./start-frontend.sh

# Celery ì›Œì»¤ë§Œ ì‹œìž‘
./start-celery.sh

# Flowerë§Œ ì‹œìž‘
./start-flower.sh
```

### 7.3 ë¡œê·¸ í™•ì¸

```bash
# ì‹¤ì‹œê°„ ë°±ì—”ë“œ ë¡œê·¸
tail -f logs/backend.log

# ì‹¤ì‹œê°„ í”„ë¡ íŠ¸ì—”ë“œ ë¡œê·¸
tail -f logs/frontend.log

# ëª¨ë“  ë¡œê·¸ ë™ì‹œ í™•ì¸
tail -f logs/*.log
```

### 7.4 ì„¤ì • íŒŒì¼ ê´€ë¦¬

#### ë°±ì—”ë“œ í™˜ê²½ ë³€ìˆ˜

```bash
# íŒŒì¼ ìœ„ì¹˜
/workspace/exlm-app/backend/.env

# API í‚¤ ì„¤ì • (ì‹¤ì œ í‚¤ë¡œ êµì²´)
OPENAI_API_KEY=your_actual_openai_key
ANTHROPIC_API_KEY=your_actual_anthropic_key
GOOGLE_API_KEY=your_actual_google_key
HF_TOKEN=your_actual_huggingface_token
```

#### í”„ë¡ íŠ¸ì—”ë“œ í™˜ê²½ ë³€ìˆ˜

```bash
# íŒŒì¼ ìœ„ì¹˜
/workspace/exlm-app/frontend/.env.local

# ë‚´ìš© (ìžë™ ì„¤ì •ë¨)
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_WS_URL=ws://localhost:8000
```

### 7.5 ì—…ë°ì´íŠ¸ ë°©ë²•

```bash
cd /workspace/exlm-app

# ì„œë¹„ìŠ¤ ì¤‘ì§€
./stop-all.sh

# ìµœì‹  ì½”ë“œ ê°€ì ¸ì˜¤ê¸°
git pull origin main

# ë°±ì—”ë“œ ì˜ì¡´ì„± ì—…ë°ì´íŠ¸ (í•„ìš”ì‹œ)
cd backend
source venv/bin/activate
pip install -r requirements-gpu.txt -q

# í”„ë¡ íŠ¸ì—”ë“œ ì˜ì¡´ì„± ì—…ë°ì´íŠ¸ (í•„ìš”ì‹œ)
cd ../frontend
npm install
npm run build

# ì„œë¹„ìŠ¤ ìž¬ì‹œìž‘
cd ..
./start-all.sh
```

## ðŸŽ‰ ì„±ê³µ í™•ì¸

ì„¤ì¹˜ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆë‹¤ë©´:

1. âœ… ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì™„ë£Œ ë©”ì‹œì§€ í™•ì¸
2. âœ… `./status.sh` ì‹¤í–‰ ì‹œ ëª¨ë“  ì„œë¹„ìŠ¤ ì‹¤í–‰ ì¤‘
3. âœ… `curl http://localhost:8000/api/v1/health` ì‘ë‹µ í™•ì¸
4. âœ… RunPod í¬íŠ¸ ì„¤ì • ì™„ë£Œ
5. âœ… ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ Frontend URL ì ‘ì† ê°€ëŠ¥
6. âœ… GPU ì¸ì‹ ë° ì‚¬ìš© ê°€ëŠ¥

## ðŸ’¡ íŒ

### íš¨ìœ¨ì ì¸ ì‚¬ìš©ë²•

1. **Screen/Tmux ì‚¬ìš©**: SSH ì—°ê²°ì´ ëŠì–´ì ¸ë„ ì„œë¹„ìŠ¤ ìœ ì§€
2. **ë¡œê·¸ ëª¨ë‹ˆí„°ë§**: ê°œë°œ ì¤‘ì—ëŠ” ì‹¤ì‹œê°„ ë¡œê·¸ í™•ì¸
3. **API í‚¤ ì„¤ì •**: ì‹¤ì œ ì‚¬ìš© ì „ì— ë°˜ë“œì‹œ API í‚¤ ì„¤ì •
4. **ì •ê¸°ì  ë°±ì—…**: ì¤‘ìš”í•œ ë°ì´í„°ëŠ” ì •ê¸°ì ìœ¼ë¡œ ë°±ì—…

### ê°œë°œ ëª¨ë“œ

```bash
# ê°œë°œ ì¤‘ì—ëŠ” ê°œë³„ ì„œë¹„ìŠ¤ ì‹¤í–‰ ê¶Œìž¥
./start-backend.sh    # í„°ë¯¸ë„ 1
./start-frontend.sh   # í„°ë¯¸ë„ 2
./start-celery.sh     # í„°ë¯¸ë„ 3
```

### ë¹„ìš© ìµœì í™”

1. **Spot ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©**: 70% í• ì¸
2. **ìžë™ ì¢…ë£Œ ì„¤ì •**: ì‚¬ìš©í•˜ì§€ ì•Šì„ ë•Œ ìžë™ ì¢…ë£Œ
3. **ì ì ˆí•œ GPU ì„ íƒ**: ìž‘ì—…ì— ë§žëŠ” GPU ì„ íƒ

ì´ì œ RunPodì—ì„œ EXLM í”Œëž«í¼ì„ ì™„ì „ížˆ ì„¤ì¹˜í•˜ê³  ì‚¬ìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤! ðŸš€
